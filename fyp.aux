\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{kour2014real}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{3}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Motivation}{3}{subsection.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Some Segmented images : Row-1 has the input images and row 2 has the output images also known as the segmented images or the segmentation maps}}{3}{figure.1}\protected@file@percent }
\newlabel{fig:1}{{1}{3}{Some Segmented images : Row-1 has the input images and row 2 has the output images also known as the segmented images or the segmentation maps}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Objective}{4}{subsection.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The cells and a certain box showing the areas of possible interest}}{4}{figure.2}\protected@file@percent }
\newlabel{fig:2}{{2}{4}{The cells and a certain box showing the areas of possible interest}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Gradcam or the regions in the input image that most affect the output in the image}}{4}{figure.3}\protected@file@percent }
\newlabel{fig:3}{{3}{4}{Gradcam or the regions in the input image that most affect the output in the image}{figure.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Organization of the Report}{5}{subsection.1.3}\protected@file@percent }
\citation{greenberg2006improved}
\citation{wang2008structure}
\citation{kurt2012medical}
\citation{montagnat2003anisotropic}
\citation{atkins1998fully}
\@writefile{toc}{\contentsline {section}{\numberline {2}Literature Review / Related works}{6}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Classical Image Processing}{6}{subsection.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Tumor segmentation}}{6}{figure.4}\protected@file@percent }
\newlabel{fig:4}{{4}{6}{Tumor segmentation}{figure.4}{}}
\citation{vrooman2007multi}
\citation{steenwijk2013accurate}
\citation{havaei2014efficient}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Classical Machine Learning}{7}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}KNN based Methods}{7}{subsubsection.2.2.1}\protected@file@percent }
\citation{ng2006medical}
\citation{dhanachandra2015image}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}K Means Clustering Based Methods}{8}{subsubsection.2.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Segmentation using k means clustering}}{8}{figure.5}\protected@file@percent }
\newlabel{fig:5}{{5}{8}{Segmentation using k means clustering}{figure.5}{}}
\citation{long2015fully}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Deep Learning Methods}{9}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Conv Encoder-Decoder Architecture}{9}{subsubsection.2.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces An encoder decoder based architecture where a constricting encoder reduces the image to a latent space $z$ and a decoder extracts a segmentation map from this feature space. The feature space effectively contains the data of all pattens and characteristics of the image. Effective construction of this is the key to such models}}{9}{figure.6}\protected@file@percent }
\newlabel{fig:8}{{6}{9}{An encoder decoder based architecture where a constricting encoder reduces the image to a latent space $z$ and a decoder extracts a segmentation map from this feature space. The feature space effectively contains the data of all pattens and characteristics of the image. Effective construction of this is the key to such models}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces "Multi resolution encoding in the feature space"}}{10}{figure.7}\protected@file@percent }
\newlabel{fig:9}{{7}{10}{"Multi resolution encoding in the feature space"}{figure.7}{}}
\citation{ronneberger2015u}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}U-Nets}{11}{subsubsection.2.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces U-net architecture example for 32x32 pixels in the lowest resolution. Each bluebox corresponds to a multi-channel feature map. The number of channels is denotedon top of the box. The x-y-size is provided at the lower left edge of the box. Whiteboxes represent copied feature maps. The arrows denote the different operations.}}{11}{figure.8}\protected@file@percent }
\newlabel{fig:6}{{8}{11}{U-net architecture example for 32x32 pixels in the lowest resolution. Each bluebox corresponds to a multi-channel feature map. The number of channels is denotedon top of the box. The x-y-size is provided at the lower left edge of the box. Whiteboxes represent copied feature maps. The arrows denote the different operations}{figure.8}{}}
\newlabel{softmax}{{1}{12}{U-Nets}{equation.2.1}{}}
\newlabel{crossentropy}{{2}{12}{U-Nets}{equation.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces A segmentation map using UNET. Note that each pixel in the given segmentation map is one of 3 classes of the 3 different colours}}{12}{figure.9}\protected@file@percent }
\newlabel{fig:7}{{9}{12}{A segmentation map using UNET. Note that each pixel in the given segmentation map is one of 3 classes of the 3 different colours}{figure.9}{}}
\newlabel{weightmap}{{3}{12}{U-Nets}{equation.2.3}{}}
\citation{selvaraju2017grad}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3}Grad-CAM : Visual Explanations from Deep Networks via Gradient-based Localization}{13}{subsubsection.2.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Class Activation Maps achieved through this paper. Note the heatmap coressponds only to those regions which cause the class to be activated. Especially the ResNet GradCAM (Extreme Right)}}{13}{figure.10}\protected@file@percent }
\newlabel{fig:10}{{10}{13}{Class Activation Maps achieved through this paper. Note the heatmap coressponds only to those regions which cause the class to be activated. Especially the ResNet GradCAM (Extreme Right)}{figure.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces The proposed methodology of achieving GradCAM}}{14}{figure.11}\protected@file@percent }
\newlabel{fig:11}{{11}{14}{The proposed methodology of achieving GradCAM}{figure.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Proposed Methodology}{15}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.0.1}The Problem Statement}{15}{subsubsection.3.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.0.2}Dataset}{15}{subsubsection.3.0.2}\protected@file@percent }
\bibstyle{unsrt}
\bibdata{references}
\bibcite{kour2014real}{1}
\bibcite{greenberg2006improved}{2}
\bibcite{wang2008structure}{3}
\bibcite{kurt2012medical}{4}
\bibcite{montagnat2003anisotropic}{5}
\bibcite{atkins1998fully}{6}
\bibcite{vrooman2007multi}{7}
\bibcite{steenwijk2013accurate}{8}
\bibcite{havaei2014efficient}{9}
\bibcite{ng2006medical}{10}
\bibcite{dhanachandra2015image}{11}
\bibcite{long2015fully}{12}
\bibcite{ronneberger2015u}{13}
\bibcite{selvaraju2017grad}{14}
\@writefile{toc}{\contentsline {section}{\numberline {4}Bibliography}{16}{section.4}\protected@file@percent }
